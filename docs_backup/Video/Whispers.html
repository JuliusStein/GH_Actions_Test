

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta content="Topic: Vision module, Difficulty: Easy, Category: Section" name="description" />
<meta content="whispers algorithm, clustering images" name="keywords" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Whispers Algorithm &mdash; CogWorks</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/my_theme.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Language Module" href="../language.html" />
    <link rel="prev" title="Vision Module Capstone" href="FacialRecognition.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> CogWorks
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Table of Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../intro.html">CogWorks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pre_reqs.html">Course Pre-Requisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supplemental_math.html">Supplemental Math Materials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../audio.html">Audio Module</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../vision.html">Vision Module</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="prereqs.html">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro_ml.html">A Brief Introduction to Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="Linear_Regression.html">Baby Steps Towards Machine Learning: Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exercises/Data_Exploration.html">Exercises: Exploring A Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="Gradient_Descent.html">Gradient-Based Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="Automatic_Differentiation.html">Automatic Differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exercises/Linear_Regression_Exercise.html">Exercises: Fitting a Linear Model with Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="What_Does_Learning_Mean.html">Where is the “Learning” in All of This?</a></li>
<li class="toctree-l2"><a class="reference internal" href="Supervised_Learning_and_Modeling.html">Supervised Learning Using Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="FacialRecognition.html">Vision Module Capstone</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Whispers Algorithm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Unsupervised-Learning">Unsupervised Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Breaking-Down-the-Algorithm">Breaking Down the Algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Key-Points">Key Points</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Whispers-Algorithm-With-Weighted-Edges">Whispers Algorithm With Weighted Edges</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Team-Tasks">Team Tasks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Taking-it-Further">Taking it Further</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../language.html">Language Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cheat_sheet.html">Cheat Sheets</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">CogWorks</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../vision.html">Vision Module</a> &raquo;</li>
        
      <li>Whispers Algorithm</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/Video/Whispers.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Whispers-Algorithm">
<h1>Whispers Algorithm<a class="headerlink" href="#Whispers-Algorithm" title="Permalink to this headline">¶</a></h1>
<p>In the second part of the capstone project, we want to be able to separate a group of pictures into groups of pictures of distinct individuals such that each individual in the database has a group of pictures. Note that each picture should only contain one person. For example, there would be two correct groups of a picture of two people who are both also in other pictures. We don’t want this to happen because an image can only be in one cluster. We will be working with these pictures in the form
of a 512-dimensional face descriptor vector which we will generate using <code class="docutils literal notranslate"><span class="pre">facenet_pytorch</span></code>’s trained resnet model.</p>
<p>Notice how this problem is different from the other part of the capstone:</p>
<ul class="simple">
<li><p>There are <strong>no labels/truths</strong> accompanying each piece of data</p></li>
<li><p>We don’t know the possible “classifications” which are in this case the people that can be present in the images</p></li>
</ul>
<p>Because of these, it becomes apparent that training a neural network will not work. We couldn’t produce a loss function without knowing the <em>truths</em>, and that is necessary for the model to backpropagate and <em>learn</em>.</p>
<div class="section" id="Unsupervised-Learning">
<h2>Unsupervised Learning<a class="headerlink" href="#Unsupervised-Learning" title="Permalink to this headline">¶</a></h2>
<p>This is where <em>unsupervised learning</em> comes in. We will be revisiting this topic more formally in week three, but here is a general introduction. This learning is unsupervised because the data does not come labeled - there is no point of reference to supervise by. However, this method allows for <em>clustering</em> of data. In this case, we will be grouping images using information from the cosine similarity between their descriptor vectors.</p>
<p>Note how much easier unsupervised training can be. It is less expensive in terms of both time and money because a large amount of data doesn’t need to be labeled. In addition, large datasets for learning are not needed anymore. It is important to really understand the structure of a problem and not develop an overkill solution. If all we need is to separate a set of images into the different people contained in the images, we don’t need to find or create and label a dataset. We also don’t need
to worry about all the possible people the images could contain - or training a model.</p>
</div>
<div class="section" id="Breaking-Down-the-Algorithm">
<h2>Breaking Down the Algorithm<a class="headerlink" href="#Breaking-Down-the-Algorithm" title="Permalink to this headline">¶</a></h2>
<p>Before we dive into the implementation of the algorithm, we have to understand a structure utilized in whispers: the <strong>graph</strong>. The graph we are referring to isn’t related to the coordinate plane, but rather one with <em>nodes</em> and <em>edges</em>. Graphs are a large area of study, and we will only be touching on what is relevant for the whispers algorithm. A graph can come in various forms, but the most common graphical representation uses circles to represent nodes and lines to represent edges.</p>
<div style="text-align: center">
<p>
<img src="../_images/graph.png" alt="example graph" width=500>
</p>
</div><p>The nodes usually represent <em>things</em> and the edges the <em>relationship</em> between those things. In our case, the node represents an image and the edge a similarity to another image. Note how not all nodes have edges - think of this in our scenario as there being only one picture of a particular person in a set of images.</p>
<p>Now how do we represent a graph with <em>code</em>? A common method is known as the <strong>adjacency matrix</strong>. An adjacency matrix, <span class="math notranslate nohighlight">\(A\)</span> is an <span class="math notranslate nohighlight">\(n\)</span> by <span class="math notranslate nohighlight">\(n\)</span> matrix, with <span class="math notranslate nohighlight">\(n\)</span> being the number of nodes in the graph. <span class="math notranslate nohighlight">\(A_{i, j}\)</span> represents the relationship between nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>. In our case, <span class="math notranslate nohighlight">\(A_{i, j}\)</span> shows whether two nodes have an edge or not - <span class="math notranslate nohighlight">\(1\)</span> could signify having an edge and <span class="math notranslate nohighlight">\(0\)</span> not having one.</p>
<div style="text-align: center">
<p>
<img src="../_images/adj_matrix.png" alt="adjacency matrix" width=500>
</p>
</div><p>The indices in the matrix are representing nodes. Implementing a <code class="docutils literal notranslate"><span class="pre">node</span></code> class is recommended to keep things neat. Referring to the <code class="docutils literal notranslate"><span class="pre">node.py</span></code> class that is prewritten can be helpful. As a rule of thumb, we want the <code class="docutils literal notranslate"><span class="pre">node</span></code> object to include the following information:</p>
<ul class="simple">
<li><p>label (which cluster it is a part of)</p></li>
<li><p>ID (a unique value in <span class="math notranslate nohighlight">\([0,n-1]\)</span>, which can be the node’s index in the adjacency matrix)</p></li>
<li><p>neighbors (a list of the ID’s of the node’s neighbors)</p></li>
</ul>
<p>The following steps outline the flow of the whispers algorithm:</p>
<ol class="arabic simple">
<li><p>Set up an adjacency matrix based on a cutoff</p>
<ul class="simple">
<li><p>There is only an edge between two nodes, or images, if the two face descriptor vectors are “close enough” (note that when using cosine similarities, this translates to the <em>distance</em> between the vectors being <strong>less</strong> than the designated cutoff)</p></li>
<li><p>Initially each node has a unique label - the colors represent different labels</p></li>
</ul>
</li>
</ol>
<div style="text-align: center">
<p>
<img src="../_images/whispers_initial.png" alt="whispers initial graph" width=500>
</p>
</div><ol class="arabic simple" start="2">
<li><p>Pick a random node</p></li>
<li><p>Count the frequency of the labels (each corresponding to a cluster) of its neighbors</p></li>
<li><p>The current node takes on the label of the most frequent label determined in the previous step</p>
<ul class="simple">
<li><p>In the case of a tie, randomly choose a label from those that are tied</p></li>
</ul>
</li>
<li><p>Repeat this until the process converges (no change in number of labels) or a max number of iterations is reached</p></li>
</ol>
<p>The previous four steps can be visualized as follows:</p>
<p>Iteration 1:</p>
<div style="text-align: center">
<p>
<img src="../_images/whispers_step1.png" alt="whispers step 1" width=500>
</p>
</div><p>Iteration 2:</p>
<div style="text-align: center">
<p>
<img src="../_images/whispers_step2.png" alt="whispers step 2" width=500>
</p>
</div><p>Iteration 3:</p>
<div style="text-align: center">
<p>
<img src="../_images/whispers_step3.png" alt="whispers step 3" width=500>
</p>
</div><p>In the last iteration shown, the current node would become orange because orange is the most frequent label among its neighbors. When the number of labels converges, the end result could look like this:</p>
<div style="text-align: center">
<p>
<img src="../_images/whispers_result.png" alt="whispers final graph" width=500>
</p>
</div><p>The final graph represents how the algorithm found three clusters of images, which corresponds to three different people.</p>
</div>
<div class="section" id="Key-Points">
<h2>Key Points<a class="headerlink" href="#Key-Points" title="Permalink to this headline">¶</a></h2>
<p>Some key ideas to keep in mind are:</p>
<ul class="simple">
<li><p>We want edges between nodes we are confident are related (images whose face descriptors are similar within a set cutoff, which can be guided by a little experimentation)</p></li>
<li><p>We also want edges between nodes whose relationship is questionable - as we saw in the example graphs, some images had edges with others which were of a different person (we can accomplish this by having a looser cutoff)</p></li>
<li><p>We don’t want edges between all pairs of nodes</p></li>
<li><p>We want to have a <em>max</em> set number of iterations to run because there is a possibility that convergence will never occur</p></li>
<li><p>Because the first node and some labels are chosen randomly, there is a possibility of getting different results on different runs of the program on the same set of images</p></li>
<li><p>Because of the variability caused by this randomness, the whispers algorithm isn’t meant for really small sets of images - think about it like there is more scope for “correction” when there is an erroneous initial pairing of pictures in a large set</p></li>
<li><p>An image can only be in one cluster at any given iteration</p></li>
<li><p>For a better implementation of the whispers algorithm, use edge <em>weights</em> to aid choosing labels (refer to the next section)</p></li>
</ul>
</div>
<div class="section" id="Whispers-Algorithm-With-Weighted-Edges">
<h2>Whispers Algorithm With Weighted Edges<a class="headerlink" href="#Whispers-Algorithm-With-Weighted-Edges" title="Permalink to this headline">¶</a></h2>
<p>We know that the closer together descriptor vectors are, the more similar the corresponding images are. However, in the implementation of the algorithm above, we are only using the vectors to determine whether nodes have edges or not. When a node has a tie among the frequency of the labels in its neighbors, we are randomly choosing a label from among those tied. However, what if we used the cosine similarity in determining which label to take on for each node? This would result in a more
accurate choice of label, and in less sporadic behavior in smaller sets of images. A nuance in implementation would be to weight our edges using <span class="math notranslate nohighlight">\(1/x^2\)</span>, with <span class="math notranslate nohighlight">\(x\)</span> being the cosine <em>distance</em> between the descriptor vectors. For convenience, we will be using cosine distance, which is equivalent to <span class="math notranslate nohighlight">\(1 - \text{cosine similarity}\)</span>. This scaling makes it easier to find images that are truly close and of the same person - try it both with and without the weighting and see if a
difference is noticeable. Now what does weighting an edge mean? It means that instead of there being a binary distinction in terms of connection between nodes (connected or not), there will be a scale among those that are connected. The ones that are closer in similarity will have a larger weight, which is determined using the <span class="math notranslate nohighlight">\(1/x^2\)</span> from above. Recall that cosine similarity returns a value from <span class="math notranslate nohighlight">\(0\)</span> to <span class="math notranslate nohighlight">\(1\)</span>, with <span class="math notranslate nohighlight">\(0\)</span> meaning two vectors are identical and <span class="math notranslate nohighlight">\(1\)</span> meaning
they are completely different (orthogonal). Using the <span class="math notranslate nohighlight">\(1/x^2\)</span> weighting results in a large weight for similar vectors. Implementing this is quite similar to what we had previously. Instead of simply putting a <span class="math notranslate nohighlight">\(1\)</span> in the adjacency matrix to signify an edge, we will have <span class="math notranslate nohighlight">\(A_{i, j}\)</span> contain <span class="math notranslate nohighlight">\(1/x^2\)</span>.</p>
<div style="text-align: center">
<p>
<img src="../_images/adj_mat_weighted.png" alt="adjacency matrix of a weighted graph" width=500>
</p>
</div><p>Now determining which label to take on for each node can be broken down like this:</p>
<ul class="simple">
<li><p>have a weight sum corresponding to each label among the node’s neighbors</p></li>
<li><p>for each neighbor, the weight of the edge between it and the node will be added to the sum corresponding to the neighbor’s label</p></li>
<li><p>the node will take on the label with the highest corresponding weight sum</p></li>
</ul>
<p>The process can be visualized as follows:</p>
<p>Iteration 1:</p>
<div style="text-align: center">
<p>
<img src="../_images/whispers_weighted_step1.png" alt="whispers step 1" width=500>
</p>
</div><p>Iteration 2:</p>
<div style="text-align: center">
<p>
<img src="../_images/whispers_weighted_step2.png" alt="whispers step 2" width=500>
</p>
</div><p>Iteration 3:</p>
<div style="text-align: center">
<p>
<img src="../_images/whispers_weighted_step3.png" alt="whispers step 3" width=500>
</p>
</div><p>Notice how the weighted edges reduced the need to randomly choose a label. Using this method, choosing labels took place with an additional piece of information: a quantified similarity between a node and its neighboring nodes.</p>
<div style="text-align: center">
<p>
<img src="../_images/whispers_weighted_result.png" alt="whispers better result" width=500>
</p>
</div><p>The resulting graph from the running the weighted whispers algorithm is different from the one obtained using the normal algorithm! Some of the clusters are composed of the same nodes, but have a different label. This doesn’t correlate to an actual difference in result - as long as the same images are grouped together, their corresponding label has no added significance. Moreover, this subtlety goes to show the role randomness can play in the whispers algorithm. However, a significant difference
from before is the number of clusters: there are four instead of three. The cluster distinguished by the black label was previously grouped with another cluster. The implication could be that the normal whispers algorithm grouped two peoples’ pictures together. There are a few ways that chance could have played out that resulted in the merging of clusters. It could be a good exercise to think through one or two. Regardless, the increased robustness of the weighted whispers algorithm corresponds
to leaving much fewer decisions to random chance. Overall, this results in the weighted algorithm having a higher accuracy.</p>
</div>
<div class="section" id="Team-Tasks">
<h2>Team Tasks<a class="headerlink" href="#Team-Tasks" title="Permalink to this headline">¶</a></h2>
<p>While everyone should understand the whispers algorithm, one to two people working on implementing it is likely enough. Those who implement it could share their takeaways with the rest of the team.</p>
</div>
<div class="section" id="Taking-it-Further">
<h2>Taking it Further<a class="headerlink" href="#Taking-it-Further" title="Permalink to this headline">¶</a></h2>
<p>These are ideas to take your project further if your team has the time:</p>
<ul class="simple">
<li><p>Display and label the results of the clustering (one possibility is in a grid view)</p></li>
<li><p>When the program is run on a folder of images, have it automatically create folders of the different people/clusters with the corresponding images in them</p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../language.html" class="btn btn-neutral float-right" title="Language Module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="FacialRecognition.html" class="btn btn-neutral float-left" title="Vision Module Capstone" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Ryan Soklaski

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>