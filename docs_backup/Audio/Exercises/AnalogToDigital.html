

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta content="Topic: recording sound, Category: Exercises" name="description" />
<meta content="analog, digital, pcm, pulse code modulation, sample rate, bit depth, nyquist" name="keywords" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Exercises: Analog to Digital Encoding &mdash; CogWorks</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/my_theme.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Decomposing Audio Signals: Fourier Analysis" href="../fourier_analysis.html" />
    <link rel="prev" title="Exercises: Working with the Microphone" href="WorkingWithMic.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> CogWorks
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Table of Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../intro.html">CogWorks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pre_reqs.html">Course Pre-Requisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../supplemental_math.html">Supplemental Math Materials</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../audio.html">Audio Module</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../prereqs.html">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="../physics-of-sound.html">The Basics of Sound</a></li>
<li class="toctree-l2"><a class="reference internal" href="AudioSignalBasics.html">Exercises: Basics of Sound Waves</a></li>
<li class="toctree-l2"><a class="reference internal" href="../recording_sound.html">Microphones: Recording Sound as an Analog Signal</a></li>
<li class="toctree-l2"><a class="reference internal" href="../digitizing_signals.html">Digitizing an Analog Signal</a></li>
<li class="toctree-l2"><a class="reference internal" href="WorkingWithMic.html">Exercises: Working with the Microphone</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Exercises: Analog to Digital Encoding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Describing-Our-Analog-Signal">Describing Our Analog Signal</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Reviewing-the-Sampling-Utilities-from-the-Reading-Materials">Reviewing the Sampling Utilities from the Reading Materials</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Creating-an-End-to-End-Analog-to-Digital-Conversion-Function">Creating an End-to-End Analog-to-Digital Conversion Function</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Testing-Our-Code">Testing Our Code</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Examining-the-Effects-of-Sampling-Rate-and-Bit-Depth">Examining the Effects of Sampling Rate and Bit-Depth</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Hearing-the-Effects-of-Sampling-Rate-and-Bit-Depth">Hearing the Effects of Sampling Rate and Bit-Depth</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../fourier_analysis.html">Decomposing Audio Signals: Fourier Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../discrete_fourier_transforms.html">The Discrete Fourier Transform (DFT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="BasicsOfDFT.html">Exercises: Basics of DFTs</a></li>
<li class="toctree-l2"><a class="reference internal" href="DFTOfVariousSignals.html">Exercises: DFTs of Various Signals</a></li>
<li class="toctree-l2"><a class="reference internal" href="ApplicationsOfDFTs.html">Exercises: Applications of DFTs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro_spectrograms.html">Introduction to Spectrogram Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="spectrogram.html">Exercise: Creating Our Own Spectrogram</a></li>
<li class="toctree-l2"><a class="reference internal" href="../audio_features.html">Matching Audio Recordings</a></li>
<li class="toctree-l2"><a class="reference internal" href="PeakFinding.html">Exercises: Finding Local Peaks in a 2-D Array</a></li>
<li class="toctree-l2"><a class="reference internal" href="../capstone_summary.html">Capstone Project: Song Recognition</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../vision.html">Vision Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../language.html">Language Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cheat_sheet.html">Cheat Sheets</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">CogWorks</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../audio.html">Audio Module</a> &raquo;</li>
        
      <li>Exercises: Analog to Digital Encoding</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/Audio/Exercises/AnalogToDigital.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    min-width: 5ex;
    padding-top: 0.3rem;
    padding-right: 0.3rem;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 0.3rem;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Exercises:-Analog-to-Digital-Encoding">
<h1>Exercises: Analog to Digital Encoding<a class="headerlink" href="#Exercises:-Analog-to-Digital-Encoding" title="Permalink to this headline">¶</a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import numpy as np
import librosa
import matplotlib.pyplot as plt
from IPython.display import Audio
from typing import Union, Callable, Tuple
from pathlib import Path

%matplotlib notebook
</pre></div>
</div>
</div>
<div class="section" id="Describing-Our-Analog-Signal">
<h2>Describing Our Analog Signal<a class="headerlink" href="#Describing-Our-Analog-Signal" title="Permalink to this headline">¶</a></h2>
<p>(1.3.1) Write a function <code class="docutils literal notranslate"><span class="pre">analog_signal</span></code> that takes in a float or a NumPy array of times and evaluates the following “Logistic Cumulative Distribution Function” at those times <span class="math">\begin{equation}
f(t)=\frac{1}{1+e^{-10(t-1)}}.
\end{equation}</span></p>
<p>Note that the choice of this function is not particularly important, and the remaining exercises can be done by rewriting <code class="docutils literal notranslate"><span class="pre">analog_signal</span></code> to be any function of interest.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def analog_signal(times: np.ndarray) -&gt; np.ndarray:
    &quot;&quot;&quot;
    Given an array of times, returns the value of an analog signal at those times.

    Parameters
    ----------
    times : numpy.ndarray
        The time(s) at which to evaluate the analog signal.

    Returns
    -------
    numpy.ndarray
        The value of the analog signal at the given times.
    &quot;&quot;&quot;
    # STUDENT CODE HERE
</pre></div>
</div>
</div>
</div>
<div class="section" id="Reviewing-the-Sampling-Utilities-from-the-Reading-Materials">
<h2>Reviewing the Sampling Utilities from the Reading Materials<a class="headerlink" href="#Reviewing-the-Sampling-Utilities-from-the-Reading-Materials" title="Permalink to this headline">¶</a></h2>
<p>We will now investigate how the process of PCM can affect the fidelity of our audio signal. Let’s start by defining a few functions. If you have not completed the <strong>Writing a Sampler</strong> and <strong>Quantization</strong> reading comprehension exercises <a class="reference external" href="https://rsokl.github.io/CogWeb/Audio/digitizing_signals.html">from the previous section</a>, you may wish to go back and work those problems before proceeding here.</p>
<p>Below are two functions, <code class="docutils literal notranslate"><span class="pre">temporal_sampler</span></code> and <code class="docutils literal notranslate"><span class="pre">quantize</span></code>, which in tandem allow us to sample and quantize a given analog signal to construct a digital signal.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def temporal_sampler(
    signal: Callable[[np.ndarray], np.ndarray], *, duration: float, sampling_rate: float
) -&gt; Tuple[np.ndarray, np.ndarray]:
    &quot;&quot;&quot;
    Extracts samples from an analog signal according to the specified sampling rate,
    returning the times and the corresponding samples extracted at those times.

    Parameters
    ----------
    signal : Callable[[ndarray], ndarray]
        Another Python function (i.e. a &quot;callable&quot;), which behaves like f(t)
        and accepts a time value (in seconds) as an input and returns a
        measurement (e.g. in volts) as an output. You can expect this to behave like
        a vectorized function i.e. it can be passed a NumPy-array of input times
        and it will return a corresponding array of measurements.

    duration : float
        The duration of the signal, specified in seconds (a non-negative float)

    sampling_rate : float
        The sampling rate specified in Hertz.

    Returns
    -------
    (times, samples) : Tuple[ndarray, ndarray]
        The shape-(N,) array of times and the corresponding shape-(N,) array
        samples extracted from the analog signal

    &quot;&quot;&quot;
    N_samples = np.floor(sampling_rate * duration) + 1

    # shape-(N,) array of times at which we sample the analog signal
    times = np.arange(N_samples) * (1 / sampling_rate)  # seconds

    # shape-(N,) array of samples extracted from the analog signal
    samples = signal(times)

    return times, samples


def quantize(samples: np.ndarray, bit_depth: int) -&gt; np.ndarray:
    &quot;&quot;&quot;
    Given an array of N samples and a bit-depth of M, return the array of
    quantized samples derived from the domain [samples.min(), samples.max()]
    that has been quantized into 2**M evenly-spaced values.

    Parameters
    ----------
    samples : numpy.ndarray, shape-(N,)
        An array of N samples

    bit_depth: int
        The bit-depth, M, used to quantize the samples among
        2**M evenly spaced values spanning [samples.min(), samples.max()].

    Returns
    -------
    quantized_samples : numpy.ndarray, shape-(N,)
        The corresponding array where each sample has been replaced
        by the nearest quantized value

    Examples
    --------
    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; samples = np.array([0, .25, .75, 1])
    &gt;&gt;&gt; quantize(samples, 1) # quantize among 2 values
    array([0., 0., 1., 1.])
    &gt;&gt;&gt; quantize(samples, 1) # quantize among 4 values
    array([0., 0.3333, .6666, 1.])
    &quot;&quot;&quot;

    assert bit_depth &lt;= 14, &quot;Exceeding this bit-depth might tank your computer!&quot;

    # create the 2**M evenly-spaced quantized values,
    # spanning [samples.min(), samples.max()]
    quantized_values = np.linspace(samples.min(), samples.max(), 2 ** bit_depth)

    # Broadcast subtract: shape-(N, 1) w/ shape-(M**2,) -&gt; shape(N, M**2)
    # `abs_differences[i]` is the absolute difference between sample-i and
    # each of the M**2 quantized values
    abs_differences = np.abs(samples[:, np.newaxis] - quantized_values)

    # For each sample, find which quantized value it is closest to.
    # Produced shape-(N,) array on indices on [0, 2**M)
    bin_lookup = np.argmin(abs_differences, axis=1)

    # Populate a shape-(N,) array, where each sample has been
    # replaced by its nearest quantized value. This leverages
    # advanced integer-array indexing
    return quantized_values[bin_lookup]
</pre></div>
</div>
</div>
</div>
<div class="section" id="Creating-an-End-to-End-Analog-to-Digital-Conversion-Function">
<h2>Creating an End-to-End Analog-to-Digital Conversion Function<a class="headerlink" href="#Creating-an-End-to-End-Analog-to-Digital-Conversion-Function" title="Permalink to this headline">¶</a></h2>
<p>(1.3.2) Using the above functions, write a function <code class="docutils literal notranslate"><span class="pre">analog_to_digital</span></code> that takes in</p>
<ul class="simple">
<li><p>an analog signal (a Python-function <span class="math notranslate nohighlight">\(f(t)\)</span>)</p></li>
<li><p>sampling rate (<span class="math notranslate nohighlight">\(f_s\)</span>)</p></li>
<li><p>bit-depth (<span class="math notranslate nohighlight">\(N_d\)</span>)</p></li>
<li><p>signal duration (<span class="math notranslate nohighlight">\(T\)</span>)</p></li>
</ul>
<p>and yields a tuple containing</p>
<ol class="arabic simple">
<li><p>the times, <span class="math notranslate nohighlight">\((t_n)_{n=0}^{N-1}\)</span>, at which the samples were taken</p></li>
<li><p>the corresponding digital samples, <span class="math notranslate nohighlight">\((f(t_n))_{n=0}^{N-1}\)</span>, extracted from the analog signal at those times</p></li>
</ol>
<p>Hint: you will first want to extract temporal samples from the analog signal, then quantize those samples. Given the functions provided above, this should be a relatively short/simple function.</p>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">*</span></code> in the following function signature makes <code class="docutils literal notranslate"><span class="pre">sampling_rate</span></code>, <code class="docutils literal notranslate"><span class="pre">bit_depth</span></code>, and <code class="docutils literal notranslate"><span class="pre">duration</span></code> <a class="reference external" href="https://www.pythonlikeyoumeanit.com/Module2_EssentialsOfPython/Functions.html#Arguments">“keyword-only” arguments</a> – they can only be passed their values by name when invoking the function. This is so the user can’t accidentally flip values for, say, the duration and the sampling rate.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def analog_to_digital(
    analog_signal: Callable[[np.ndarray], np.ndarray],
    *,
    sampling_rate: float,
    bit_depth: int,
    duration: float
) -&gt; Tuple[np.ndarray, np.ndarray]:
    &quot;&quot;&quot;
    Digitizes a given analog signal based on desired sampling rate and bit-depth.

    Parameters
    ----------
    analog_signal : Callable[[ndarray], ndarray]
        Another Python function, f(t), which accepts a time value (in seconds) as
        an input and returns a measurement (in volts) as an output.

    sampling_rate : float
        The sampling rate specified in Hertz.

    bit_depth: int
        The bit-depth, M, used to quantize the samples among
        2**M evenly spaced values spanning [samples.min(), samples.max()].

    duration : float
        The duration of the signal, specified in seconds (a non-negative float).

    Returns
    -------
    (times, digital_signal) : Tuple[ndarray, ndarray]
        The shape-(N,) array of times and the corresponding
        shape-(N,) array representing the digital signal.
    &quot;&quot;&quot;
    # STUDENT CODE HERE
</pre></div>
</div>
</div>
<div class="section" id="Testing-Our-Code">
<h3>Testing Our Code<a class="headerlink" href="#Testing-Our-Code" title="Permalink to this headline">¶</a></h3>
<p>Let’s test out our work so far. The following cell will plot a “continuous” version of <span class="math notranslate nohighlight">\(f(t)\)</span> (<code class="docutils literal notranslate"><span class="pre">analog_signal</span></code>), and then will use our implementation of <code class="docutils literal notranslate"><span class="pre">analog_to_digital</span></code> to plot discrete samples of the function on top of it.</p>
<p>The duration (<span class="math notranslate nohighlight">\(T\)</span>), sampling rate (<span class="math notranslate nohighlight">\(f_s\)</span>), and bit-depth (<span class="math notranslate nohighlight">\(N_d\)</span>) are set at the top of the code cell. Based on these values, do the plotted discrete samples occur at the appropriate time intervals given <span class="math notranslate nohighlight">\(f_s\)</span>? Are there the appropriate number of distinct measurement values, given <span class="math notranslate nohighlight">\(N_d\)</span>?</p>
<p>Try changing these values to see that <code class="docutils literal notranslate"><span class="pre">analog_to_digital</span></code> continues to produce the appropriate output.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># feel free to change these
duration = 2  # seconds
sample_rate = 10  # Hz
bit_depth = 2  # bits


# You don&#39;t need to change any of the remaining code
# simply read through it and then run this cell
fig, ax = plt.subplots()

# we densely sample the analog analog_signal to make it look like
# it is continuous
dense_t = np.linspace(0, duration, 10000)  # seconds
ax.plot(dense_t, analog_signal(dense_t), ls=&quot;--&quot;, alpha=0.5)


# extract samples that have been discretized in time and quantized
times, samples = analog_to_digital(
    analog_signal=analog_signal,
    duration=duration,
    sampling_rate=sample_rate,
    bit_depth=bit_depth,
)

# plot our digital samples on top of the analog signal
ax.stem(
    times,
    samples,
    &quot;red&quot;,
    markerfmt=&quot;ro&quot;,
    basefmt=&quot; &quot;,
    use_line_collection=True,
)
ax.set_xlabel(&quot;Time [seconds]&quot;)
ax.set_ylabel(&quot;Proportional to Volts&quot;)
ax.grid(True)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Examining-the-Effects-of-Sampling-Rate-and-Bit-Depth">
<h3>Examining the Effects of Sampling Rate and Bit-Depth<a class="headerlink" href="#Examining-the-Effects-of-Sampling-Rate-and-Bit-Depth" title="Permalink to this headline">¶</a></h3>
<p>(1.3.3) Let’s finally take a look at how different choices of <code class="docutils literal notranslate"><span class="pre">sampling_rate</span></code> and <code class="docutils literal notranslate"><span class="pre">bit_depth</span></code> will affect our digital signal. Below is code that will plot the digital signal for various choices of sampling rate and bits. In particular, from left to right, the columns represent bit-depths of <span class="math notranslate nohighlight">\(2\)</span>, <span class="math notranslate nohighlight">\(4\)</span>, and <span class="math notranslate nohighlight">\(8\)</span>. Top to bottom, the rows represent sampling rates of <span class="math notranslate nohighlight">\(1\:\mathrm{Hz}\)</span>, <span class="math notranslate nohighlight">\(10\:\mathrm{Hz}\)</span>, and <span class="math notranslate nohighlight">\(100\:\mathrm{Hz}\)</span>.</p>
<p>Try changing the sampling rates, bit depth, and analog signal used and see how the digital signal is affected.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>sampling_rates = [1, 10, 100]  # Hz
bit_depths = [2, 4, 8]  # bits

# run this cell - you don&#39;t need to change anything below this comment

fig, axes = plt.subplots(nrows=len(sampling_rates), ncols=len(bit_depths))

min_ = 0
max_ = 2
duration = max_ - min_

dense_times = np.linspace(min_, max_, 10 ** 5)
dense_sampling = analog_signal(dense_times)

for i, sr in enumerate(sampling_rates): # sampling rates
    for j, bits in enumerate(bit_depths): # bit-depths
        axes[i, j].plot(dense_times, dense_sampling)

        sampling_time, digital_signal = analog_to_digital(
            analog_signal, sampling_rate=sr, bit_depth=bits, duration=duration
        )
        axes[i, j].step(sampling_time, digital_signal, where=&quot;mid&quot;)

        for tic in axes[i, j].xaxis.get_major_ticks():
            tic.tick1line.set_visible(False)
            tic.tick2line.set_visible(False)
            tic.label1.set_visible(False)
            tic.label2.set_visible(False)
        for tic in axes[i, j].yaxis.get_major_ticks():
            tic.tick1line.set_visible(False)
            tic.tick2line.set_visible(False)
            tic.label1.set_visible(False)
            tic.label2.set_visible(False)

        if i == 0 or i == 2:
            if i == 0:
                axes[i, j].set_title(f&quot;N_d={bits}\nfs={sr}Hz&quot;)
            else:
                axes[i, j].set_xlabel(f&quot;N_d={bits}\nfs={sr}Hz&quot;)

        axes[i, j].grid(True)
fig.tight_layout()
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Hearing-the-Effects-of-Sampling-Rate-and-Bit-Depth">
<h2>Hearing the Effects of Sampling Rate and Bit-Depth<a class="headerlink" href="#Hearing-the-Effects-of-Sampling-Rate-and-Bit-Depth" title="Permalink to this headline">¶</a></h2>
<p><strong>A Quick Aside: Raw Strings</strong></p>
<p>We are going to be be writing strings as paths to files on our computers. This can lead to some unexpected complications that can be quite confusing at first. Consider the following Windows-format path:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;D:\Music</span><span class="se">\n</span><span class="s2">ew_song.mp3&quot;</span>
</pre></div>
</div>
<p>Let’s try printing this string in Python:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Our path contains \n, which is treated as a single newline character</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="s2">&quot;D:\Music</span><span class="se">\n</span><span class="s2">ew_song.mp3&quot;</span><span class="p">)</span>
<span class="n">D</span><span class="p">:</span>\<span class="n">Music</span>
<span class="n">ew_song</span><span class="o">.</span><span class="n">mp3</span>
</pre></div>
</div>
<p>Recall that <code class="docutils literal notranslate"><span class="pre">&quot;\n&quot;</span></code> is treated as a <em>single</em>, special character in Python; in particular, it represents a newline character. <code class="docutils literal notranslate"><span class="pre">&quot;\n&quot;</span></code> is one of several so-called escape characters (e.g. <code class="docutils literal notranslate"><span class="pre">&quot;\t&quot;</span></code> is the escape character for tab).</p>
<p>We want to avoid these escape characters from affecting our file-paths. Indeed, the <code class="docutils literal notranslate"><span class="pre">\</span></code> character is supposed to serve as a directory separator on a Windows system. Fortunately, we can tell Python to forego its interpretation of escape characters by making a string into a raw-string. We do this by pre-pending an <code class="docutils literal notranslate"><span class="pre">r</span></code> <em>before</em> the opening quotation mark of the string.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># normal string</span>
<span class="s2">&quot;hello&quot;</span>

<span class="c1"># raw string</span>
<span class="sa">r</span><span class="s2">&quot;hello&quot;</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Creating a raw-string of our path by pre-pending an</span>
<span class="c1"># r before the string prevents Python from looking for</span>
<span class="c1"># escape characters</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;D:\Music\new_song.mp3&quot;</span><span class="p">)</span>
<span class="n">D</span><span class="p">:</span>\<span class="n">Music</span>\<span class="n">new_song</span><span class="o">.</span><span class="n">mp3</span>
</pre></div>
</div>
<p>Thus it is prudent to store string paths as raw strings throughout our code.</p>
<p><strong>Back to Digitizing Signals!</strong></p>
<p>Finally let’s take a look at how we can modify music files that have already been recorded. We can use Librosa to work with music files in Python. Start by picking out a song you have on your computer, and use Librosa to load the first <span class="math notranslate nohighlight">\(11\)</span> seconds of said song.</p>
<p>Note that on Windows, you can hold Shift and right-click on your audio file; among the options that pop-up, there should be a “Copy as path” option, which is a convenient way to get a string representation of the path to that file on your computer. On MacOS, this can be similarly accomplished by right-clicking then holding Option - in the menu will be a “Copy as Pathname”, which will copy the file path to your clipboard.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># using librosa to read in audio samples from a sound file (e.g. .mp3 or .wav) as a numpy array

# The r in front to the string is to treat the string as a &quot;raw string&quot;.
# This guarantees that characters like `\n` get interpreted literally,
# and not in special ways (e.g. like a line break)
local_song_path = r&quot;path/to_a/song/on/your/computer.mp3&quot;

length = 11  # seconds

# load the digital signal for the first 11 seconds of the song
samples, sampling_rate = librosa.load(local_song_path, sr=44100, mono=True, duration=length)
</pre></div>
</div>
</div>
<p>(1.3.4) Write some simple code to investigate the following:</p>
<ul class="simple">
<li><p>What is the data type of the array <code class="docutils literal notranslate"><span class="pre">samples</span></code>?</p></li>
<li><p>What is the shape of <code class="docutils literal notranslate"><span class="pre">samples</span></code>?</p>
<ul>
<li><p>Does the number of elements in the array make sense based on the sampling rate and the duration of the clip?</p></li>
</ul>
</li>
<li><p>What are the minimum and maximum values stored in the array?</p>
<ul>
<li><p>What does this imply about the relative “loudness” songs that are loaded by librosa in this way?</p></li>
</ul>
</li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># STUDENT CODE HERE
</pre></div>
</div>
</div>
<p>You can listen to this audio clip using the following</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>Audio(samples, rate=sampling_rate)
</pre></div>
</div>
</div>
<p>(1.3.5) There is a very good chance that the recording was digitized at a sampling rate of <span class="math notranslate nohighlight">\(f_s=44,100\:\mathrm{Hz}\)</span> and with a bit-depth of <span class="math notranslate nohighlight">\(N_d=16\)</span>.</p>
<p>What would our music would sound like if it were recorded with a lower sampling rate and/or bit-depth?</p>
<p>To do this, we’ll start by re-sampling the data we loaded in, thus changing the sampling rate of the signal. Of course it would not be possible to re-sample the data at a <em>higher</em> sampling rate than that originally used, but we can still down-sample the data by skipping over samples.</p>
<p>Let’s say we wanted to sample with a sampling rate of <span class="math notranslate nohighlight">\(1,000\:\mathrm{Hz}\)</span>. We initially recorded with a sampling rate of <span class="math notranslate nohighlight">\(44,100\:\mathrm{Hz}\)</span>, meaning our digital signal has <span class="math notranslate nohighlight">\(11\:\mathrm{sec}\cdot44,100\:\mathrm{Hz}=485,100\)</span> samples. However, we want to re-sample our signal such that we only have <span class="math notranslate nohighlight">\(11\:\mathrm{sec}\cdot1,000\:\mathrm{Hz}=11,000\)</span> samples. This means that to re-sample our song at <span class="math notranslate nohighlight">\(1,000\:\mathrm{Hz}\)</span>, we will need to only take every
<span class="math notranslate nohighlight">\(\frac{485,100}{11,000}=44.1^\text{th}\)</span> sample. Since we can only skip over an integer number of samples, we will have to settle for every <span class="math notranslate nohighlight">\(\big\lfloor\frac{485,100}{11,000}\big\rfloor=44^\text{th}\)</span> sample.</p>
<p>We can “resample” our data in this way as,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">skip</span> <span class="o">=</span> <span class="mi">44</span>
<span class="n">resampled_signal</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[::</span><span class="n">skip</span><span class="p">]</span>  <span class="c1"># audio at 1000 Hz</span>
</pre></div>
</div>
<p>Now, generalize this code so that you can specify any new sampling rate (that is less than the original rate) and <code class="docutils literal notranslate"><span class="pre">skip</span></code> will be set to the correct value. Re-sample the recording at a rate of <span class="math notranslate nohighlight">\(2,000\:\mathrm{Hz}\)</span>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># STUDENT CODE HERE
</pre></div>
</div>
</div>
<p>Note that this re-sampling will not be a perfect process. You can easily check that the size of the re-sampled signal is not what you would expect it to be.</p>
<p>This has to do with the fact that we can only truly re-sample the original analog signal if we choose our new sampling rate to be a factor of the original sampling rate. To re-sample our original signal for non-factor sampling rates would require more advanced signal processing. However, we will take this method of re-sampling to be sufficient for our purposes.</p>
<p>Now, we could play our re-sampled signal out at a rate of <span class="math notranslate nohighlight">\(2,000\:\mathrm{Hz}\)</span>, but there is a good chance that your computer will not be able to actually play this. We will thus have to get a bit clever and “stretch out” our signal back to be re-played at <span class="math notranslate nohighlight">\(44,100\:\mathrm{Hz}\)</span>. We can use <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.repeat.html">numpy.repeat</a> to do this.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># &quot;stretches&quot; signal so that it can be played by audio plugin
resampled_signal = np.repeat(resampled_signal, skip)
</pre></div>
</div>
</div>
<p>Finally, replay the re-sampled signal using</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>Audio(resampled_signal, rate=44100)
</pre></div>
</div>
</div>
<p>and note how different the re-sampled audio sounds to the original song. Which of the original notes (high frequencies or low frequencies) can you still make out?</p>
<p>(1.3.6) Now that we’ve re-sampled the recording, let’s re-quantize it as well. To do this, we simply need to leverage the <code class="docutils literal notranslate"><span class="pre">quantize</span></code> function defined earlier, passing in the recording and the desired bit-depth. Again, we can’t choose a bit-depth greater than that of the original recording, but we can always choose a lower value.</p>
<p>Re-quantize the re-sampled signal with a new bit-depth of <span class="math notranslate nohighlight">\(N_b=3\)</span>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># STUDENT CODE HERE
</pre></div>
</div>
</div>
<p>Again, play the now re-quantized recording, and notice how it differs from the original clip.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># STUDENT CODE HERE
</pre></div>
</div>
</div>
<p>Go back and play with these numbers. For example, try keeping the original sampling rate but then re-quantize the song at a lower bit-rate.</p>
<p>(1.3.7) Finally let’s graphically compare our re-sampled and re-quantized song to the original. Repeat the re-sampling and re-quantization process from above, on the original samples, now with a sampling rate of <span class="math notranslate nohighlight">\(40\:\mathrm{Hz}\)</span> and a bit-depth of <span class="math notranslate nohighlight">\(4\)</span>. Then plot the first <span class="math notranslate nohighlight">\(5\)</span> seconds of each of the signals below. Use the <code class="docutils literal notranslate"><span class="pre">plot</span></code> method for the original song and the <code class="docutils literal notranslate"><span class="pre">step</span></code> method for the modified signal.</p>
<p>Play around with the choices of sampling rate and bit-depth to see how changing these values impacts the digital signal.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>sampling_rate = 40
bit_depth = 4


# Use your code from (1.4) to resample the song clip at
# the desired sampling rate. Then apply `quantize` to
# these samples with the appropriatebit-depth. Call
# the result `new_signal`.

# STUDENT CODE HERE


# Define `n_samples_orig` the number of samples associated
# with 5 seconds of an audio recording with a sampling rate
# of 44,100 Hz
# STUDENT CODE HERE

# Similarly, define `n_samples_new` the number of samples associated
# with 5 seconds of an audio recording with the sampling rate: `sampling_rate`
# STUDENT CODE HERE

fig, ax = plt.subplots(1, 1)

ax.plot(np.linspace(0, 5, n_samples_orig), samples[: n_samples_orig])
ax.step(np.linspace(0, 5, n_samples_new), new_signal[: n_samples_new], where=&quot;mid&quot;)
ax.set_xlabel(&quot;Time [seconds]&quot;)
ax.set_ylabel(&quot;Amplitude [Proportional to Volts]&quot;);
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../fourier_analysis.html" class="btn btn-neutral float-right" title="Decomposing Audio Signals: Fourier Analysis" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="WorkingWithMic.html" class="btn btn-neutral float-left" title="Exercises: Working with the Microphone" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Ryan Soklaski

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>