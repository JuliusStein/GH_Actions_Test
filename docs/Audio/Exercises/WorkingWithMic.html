

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta content="Topic: recording sound, Category: Exercises" name="description" />
<meta content="analog, digital, microphone" name="keywords" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Exercises: Working with the Microphone &mdash; CogWorks</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/my_theme.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Exercises: Analog to Digital Encoding" href="AnalogToDigital.html" />
    <link rel="prev" title="Digitizing an Analog Signal" href="../digitizing_signals.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> CogWorks
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Table of Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../intro.html">CogWorks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pre_reqs.html">Course Pre-Requisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../supplemental_math.html">Supplemental Math Materials</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../audio.html">Audio Module</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../prereqs.html">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="../physics-of-sound.html">The Basics of Sound</a></li>
<li class="toctree-l2"><a class="reference internal" href="AudioSignalBasics.html">Exercises: Basics of Sound Waves</a></li>
<li class="toctree-l2"><a class="reference internal" href="../recording_sound.html">Microphones: Recording Sound as an Analog Signal</a></li>
<li class="toctree-l2"><a class="reference internal" href="../digitizing_signals.html">Digitizing an Analog Signal</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Exercises: Working with the Microphone</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Using-the-Microphone-Python-Package">Using the Microphone Python Package</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Writing-Our-Own-Audio-Files-(Using-NumPy)">Writing Our Own Audio Files (Using NumPy)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Visualizing-an-Audio-Recording">Visualizing an Audio Recording</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="AnalogToDigital.html">Exercises: Analog to Digital Encoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../fourier_analysis.html">Decomposing Audio Signals: Fourier Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../discrete_fourier_transforms.html">The Discrete Fourier Transform (DFT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="BasicsOfDFT.html">Exercises: Basics of DFTs</a></li>
<li class="toctree-l2"><a class="reference internal" href="DFTOfVariousSignals.html">Exercises: DFTs of Various Signals</a></li>
<li class="toctree-l2"><a class="reference internal" href="ApplicationsOfDFTs.html">Exercises: Applications of DFTs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro_spectrograms.html">Introduction to Spectrogram Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="spectrogram.html">Exercise: Creating Our Own Spectrogram</a></li>
<li class="toctree-l2"><a class="reference internal" href="../audio_features.html">Matching Audio Recordings</a></li>
<li class="toctree-l2"><a class="reference internal" href="PeakFinding.html">Exercises: Finding Local Peaks in a 2-D Array</a></li>
<li class="toctree-l2"><a class="reference internal" href="../capstone_summary.html">Capstone Project: Song Recognition</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../vision.html">Vision Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../language.html">Language Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cheat_sheet.html">Cheat Sheets</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">CogWorks</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../audio.html">Audio Module</a> &raquo;</li>
        
      <li>Exercises: Working with the Microphone</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/Audio/Exercises/WorkingWithMic.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    min-width: 5ex;
    padding-top: 0.3rem;
    padding-right: 0.3rem;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 0.3rem;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Exercises:-Working-with-the-Microphone">
<h1>Exercises: Working with the Microphone<a class="headerlink" href="#Exercises:-Working-with-the-Microphone" title="Permalink to this headline">¶</a></h1>
<p>In this notebook, we will learn how to access the digitized audio recording our microphones, and access the audio samples as a numpy array of data that we can analyze and manipulate. We will write functions for writing and reading our own numpy-based audio files.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import numpy as np
import matplotlib.pyplot as plt
from IPython.display import Audio
from typing import Tuple

%matplotlib notebook
</pre></div>
</div>
</div>
<p>As discussed in the <a class="reference external" href="https://rsokl.github.io/CogWeb/Audio/digitizing_signals.html">preceding section</a>, a microphone is responsible for converting the information carried by sound waves into an analog electrical signal, which it then digitizes through a process comparable to pulse code modulation (PCM). Let’s take some time to understand how we can access the digital audio samples that are recorded by your microphone.</p>
<p>Your microphone stores the audio on buffer frames, which is just an area of RAM made for temporary storage. Buffers are typically used when there is a difference between the rate at which data is received and the rate at which it can be processed. The details of buffer frames are not especially important though. We only need to know that our digital signal will be stored as a collection of bytes in memory across a number of frames.</p>
<div class="section" id="Using-the-Microphone-Python-Package">
<h2>Using the Microphone Python Package<a class="headerlink" href="#Using-the-Microphone-Python-Package" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">microphone.record_audio</span></code> package records and digitizes an analog signal and returns a tuple containing</p>
<ol class="arabic simple">
<li><p>a list of bytes in memory corresponding to the digital signal</p></li>
<li><p>the sampling rate.</p></li>
</ol>
<p>(Remember that, in a Jupyter Notebook, you can check this by inspecting the function’s docstring with <code class="docutils literal notranslate"><span class="pre">SHIFT-TAB</span></code>)</p>
<p>For example, consider the following code</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">microphone</span> <span class="kn">import</span> <span class="n">record_audio</span>
<span class="n">listen_time</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># seconds</span>
<span class="n">frames</span><span class="p">,</span> <span class="n">sample_rate</span> <span class="o">=</span> <span class="n">record_audio</span><span class="p">(</span><span class="n">listen_time</span><span class="p">)</span>
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">sample_rate</span></code> is the sampling rate, <span class="math notranslate nohighlight">\(f_s\)</span>, used by the microphone to record the digital signal. Since all we need to know in order to reconstruct the original signal from bytes in memory are the sampling rate and the number of samples, it is extremely important that we keep track of <code class="docutils literal notranslate"><span class="pre">sample_rate</span></code>!</p>
<p>The <code class="docutils literal notranslate"><span class="pre">frames</span></code> variable is a list of bytes in memory that compose the entirety of the recorded digital signal. To anyone except a computer, the elements of <code class="docutils literal notranslate"><span class="pre">frames</span></code> are indecipherable; just try inspecting <code class="docutils literal notranslate"><span class="pre">frames[0]</span></code>.</p>
<p>To make the data useful to us, we will need to convert each of the bytes into <span class="math notranslate nohighlight">\(16\)</span>-bit integers, under the assumption that the microphone used the standard bit depth of <span class="math notranslate nohighlight">\(N_b=16\)</span>. To do so, we can use the <a class="reference external" href="https://numpy.org/doc/1.18/reference/generated/numpy.frombuffer.html">numpy.frombuffer</a> function. In particular,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">int16</span><span class="p">)</span>
</pre></div>
</div>
<p>will read in the first frame and return a 1-D NumPy array containing <span class="math notranslate nohighlight">\(16\)</span>-bit integers. In order to convert the entire digital signal into readable integers, we will need to iterate over each frame in <code class="docutils literal notranslate"><span class="pre">frames</span></code> and use <code class="docutils literal notranslate"><span class="pre">np.frombuffer(...,</span> <span class="pre">np.int16)</span></code> to convert each “frame” of bytes into an array of 16-bit integers. We can then use the <a class="reference external" href="https://numpy.org/doc/1.18/reference/generated/numpy.hstack.html">numpy.hstack</a> function to join all of these arrays together into a single array of
all of 16-bit integers that make up the digital audio recording:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Converting bytes of memory that was written to by our microphone</span>
<span class="c1"># into a single array of 16-bit integers.</span>
<span class="c1"># This array stores the digital audio data of our recording</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int16</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">frames</span><span class="p">])</span>
</pre></div>
</div>
<p>(1.2.1) Use the <code class="docutils literal notranslate"><span class="pre">record_audio</span></code> function to record and digitize an analog signal that lasts one second. Then iterate through each frame and convert the bytes into NumPy arrays of <span class="math notranslate nohighlight">\(16\)</span>-bit integers. Finally, concatenate all the NumPy arrays in order to have a single array corresponding to the full digital signal. <a class="reference external" href="https://www.pythonlikeyoumeanit.com/Module2_EssentialsOfPython/Generators_and_Comprehensions.html#List-&amp;-Tuple-Comprehensions">List comprehensions</a> using
<a class="reference external" href="https://numpy.org/doc/1.18/reference/generated/numpy.hstack.html">numpy.hstack</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># STUDENT CODE HERE
</pre></div>
</div>
</div>
<p>You can listen to the audio samples are stored in the resulting NumPy array (<em>not</em> the memory frames) using</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Listen to your recording
Audio(samples, rate=sample_rate)
</pre></div>
</div>
</div>
<p>Now that we have made our digital signal a bit more useful, let’s save our digital signal so we can work with it even when we need to restart our Jupyter Notebook kernel. Thankfully NumPy provides us with the capability to save arrays to disk (as <code class="docutils literal notranslate"><span class="pre">npy</span></code> files) with the <a class="reference external" href="https://numpy.org/doc/1.18/reference/generated/numpy.save.html">numpy.save</a> function.</p>
</div>
<div class="section" id="Writing-Our-Own-Audio-Files-(Using-NumPy)">
<h2>Writing Our Own Audio Files (Using NumPy)<a class="headerlink" href="#Writing-Our-Own-Audio-Files-(Using-NumPy)" title="Permalink to this headline">¶</a></h2>
<p>(1.2.2) Write a function that records an analog signal and <a class="reference external" href="https://www.pythonlikeyoumeanit.com/Module5_OddsAndEnds/WorkingWithFiles.html#Saving-and-Loading-NumPy-Arrays">writes the resulting digital signal to a</a> <code class="docutils literal notranslate"><span class="pre">npy</span></code> file. Remember that we will also want to save the sampling rate of the digital signal, so make the array you save have as its first element the sampling rate. In other words, <code class="docutils literal notranslate"><span class="pre">array_to_save[0]</span> <span class="pre">==</span> <span class="pre">sample_rate</span></code> and <code class="docutils literal notranslate"><span class="pre">array_to_save[1]</span> <span class="pre">==</span> <span class="pre">samples[0]</span></code>. This additional
information that we save are saving to the beginning of our array, to provide context for interpreting the rest of the data in the array, is often referred to as a “file header”.</p>
<p>An important note: we converted the bytes in the buffer frames into signed <span class="math notranslate nohighlight">\(16\)</span>-bit integers. However, the standard sampling rate of <span class="math notranslate nohighlight">\(44,100\:\mathrm{Hz}\)</span> cannot be stored as a signed <span class="math notranslate nohighlight">\(16\)</span>-bit integer (the largest signed 16-bit integer is <span class="math notranslate nohighlight">\(\pm 32,768\)</span>), meaning that in order to store <code class="docutils literal notranslate"><span class="pre">sample_rate</span></code> alongside <code class="docutils literal notranslate"><span class="pre">samples</span></code>, <code class="docutils literal notranslate"><span class="pre">array_to_save</span></code> must store <span class="math notranslate nohighlight">\(32\)</span>-bit integers instead of <span class="math notranslate nohighlight">\(16\)</span>-bit integers.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def record_and_save(listen_time: float, file_path: str):
    &quot;&quot;&quot;
    Uses microphone to record and digitize an analog signal
    and save the resulting digital signal and sampling rate to npy file.

    The first element in the saved array should store the the sample-rate;
    the remaining elements in the array should store the sampled data itself.


    Parameters
    ----------
    listen_time : float
        Length of recording in seconds.

    file_path : Union[str, pathlib.Path]
        Path to the file destination. E.g. &quot;my_audio.npy&quot; will save an audio
        file called &quot;my_audio.npy&quot; to the current working directory.
    &quot;&quot;&quot;
    # STUDENT CODE HERE
</pre></div>
</div>
</div>
<p>(1.2.3) Now that we’ve devised a way to record and save a digital signal to a file, we need a way to load that file. Write a function that loads a digital signal saved by your previous function. It should return a tuple containing</p>
<ol class="arabic simple">
<li><p>the NumPy array storing the digital signal</p></li>
<li><p>the sampling rate of the signal.</p></li>
</ol>
<p>The function <a class="reference external" href="https://numpy.org/doc/1.18/reference/generated/numpy.load.html">numpy.load</a> will be handy here.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def load_and_parse(file_path: str) -&gt; Tuple[np.ndarray, int]:
    &quot;&quot;&quot;
    Loads a saved digital signal from an npy file and returns the signal and the sampling rate.

    Parameters
    ----------
    file_path : Union[str, pathlib.Path]
        Path to the numpy-based audio file (.npy) to be loaded

    Returns
    -------
    Tuple[np.ndarray, int]
        The digital signal as a NumPy array and the sampling rate
    &quot;&quot;&quot;
    # STUDENT CODE HERE
</pre></div>
</div>
</div>
<p>Use these functions to record a <span class="math notranslate nohighlight">\(2\)</span> second recording and save a digital audio file. Then load the signal and sample rate from the audio file.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># STUDENT CODE HERE
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Listen to your recording

# STUDENT CODE HERE
</pre></div>
</div>
</div>
</div>
<div class="section" id="Visualizing-an-Audio-Recording">
<h2>Visualizing an Audio Recording<a class="headerlink" href="#Visualizing-an-Audio-Recording" title="Permalink to this headline">¶</a></h2>
<p>(1.2.4) Now that we can read the digital signal back into Python, let’s determine the times at which the analog signal was sampled. Remember, we only need to know two things to do this, the number of samples (<span class="math notranslate nohighlight">\(N\)</span>) and the sampling rate (<span class="math notranslate nohighlight">\(f_s\)</span>).</p>
<p>Define the variable <code class="docutils literal notranslate"><span class="pre">times</span></code> – a NumPy array containing the times at which the analog signal was sampled. The size of <code class="docutils literal notranslate"><span class="pre">times</span></code> should be the same as the size of the array containing the digital signal, and the final value in <code class="docutils literal notranslate"><span class="pre">times</span></code> (i.e. <code class="docutils literal notranslate"><span class="pre">times[-1]</span></code>) should be very close the initial recording length.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># STUDENT CODE HERE
</pre></div>
</div>
</div>
<p>(1.2.5) Finally, let’s plot our digital signal. First, plot the digital signal recorded by the computer. Then, plot every <span class="math notranslate nohighlight">\(441^\text{th}\)</span> sample of the digital signal; assuming the original sampling rate is the standard <span class="math notranslate nohighlight">\(f_s=44,100 \:\mathrm{Hz}\)</span>, this signal would correspond to the case where we had used a sampling rate of only <span class="math notranslate nohighlight">\(f_s=100\:\mathrm{Hz}\)</span>.</p>
<p>Think about how we can create this low-rate, re-sampled signal by simply slicing into our original signal.</p>
<p>Label your axes and include units. The values that you recorded in your microphone aren’t direct voltage measurements, but they are proportional to it – suffice it to label the <span class="math notranslate nohighlight">\(y\)</span>-axis as <code class="docutils literal notranslate"><span class="pre">&quot;Proportional</span> <span class="pre">to</span> <span class="pre">Volts&quot;</span></code></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># STUDENT CODE HERE
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="AnalogToDigital.html" class="btn btn-neutral float-right" title="Exercises: Analog to Digital Encoding" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../digitizing_signals.html" class="btn btn-neutral float-left" title="Digitizing an Analog Signal" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Ryan Soklaski

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>