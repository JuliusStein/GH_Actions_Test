

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Introduction to Autoencoders &mdash; CogWorks</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/my_theme.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> CogWorks
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Table of Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html">CogWorks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pre_reqs.html">Course Pre-Requisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../supplemental_math.html">Supplemental Math Materials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../audio.html">Audio Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../vision.html">Vision Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../language.html">Language Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cheat_sheet.html">Cheat Sheets</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">CogWorks</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
      <li>Introduction to Autoencoders</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/Language/Exercises/LinearAutoencoder.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    min-width: 5ex;
    padding-top: 0.3rem;
    padding-right: 0.3rem;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 0.3rem;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Introduction-to-Autoencoders">
<h1>Introduction to Autoencoders<a class="headerlink" href="#Introduction-to-Autoencoders" title="Permalink to this headline">¶</a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import mygrad as mg
import mynn
import numpy as np

from mygrad.nnet.initializers import he_normal
from mynn.layers.dense import dense
from mynn.losses.mean_squared_loss import mean_squared_loss
from mynn.optimizers.sgd import SGD
from mynn.optimizers.adam import Adam

import matplotlib.pyplot as plt

%matplotlib notebook
</pre></div>
</div>
</div>
<div class="section" id="1-Defining-a-Linear-Autoencoder-Model">
<h2>1 Defining a Linear Autoencoder Model<a class="headerlink" href="#1-Defining-a-Linear-Autoencoder-Model" title="Permalink to this headline">¶</a></h2>
<div class="section" id="1.1-What-Exactly-Is-An-Autoencoder?">
<h3>1.1 What Exactly Is An Autoencoder?<a class="headerlink" href="#1.1-What-Exactly-Is-An-Autoencoder?" title="Permalink to this headline">¶</a></h3>
<p>Autoencoders are a family of neural networks that can be leveraged to learn dense, abstract representations of data. These representations can often be used to make salient important, high-level features about our data. As an example of an encoder network, Facenets’s facial-recognition model could take a picture of a face and <strong>encode it</strong> into a 512-dimensional vector that allowed us to tell the difference between individuals based on their personal appearances.</p>
<p>We can think of an autoencoder as two separate neural nets: an encoder and a decoder. We pass in data to our encoder, which generates a useful, abstract representation for the data. This abstract representation of the data is then passed into the decoder, which will try to recover the original data. We train the encoder and decoder simultaneously, with the autoencoder learning to how to compress and uncompress the data in the most lossless way possible.</p>
<p>Autoencoders are a sort of hybrid supervised-unsupervised network. There <em>is</em> a truth value, but it is simply the original data (i.e., <code class="docutils literal notranslate"><span class="pre">ytrain</span> <span class="pre">=</span> <span class="pre">xtrain</span></code>). When the network is trained with <code class="docutils literal notranslate"><span class="pre">mean_squared_error</span></code> loss between the network’s outputs and inputs, gradient descent will try to find parameters that result in good encodings (representations with reduced dimensionality) that allow the decoder to recover or reconstruct the original input.</p>
<p>Our entire autoencoder can be used for de-noising data. The learning mapping to a reduced dimension can be used for visualization, clustering, compression, etc.</p>
<p>We’ll be training a neural network with two dense layers (no bias) and no activation functions:</p>
<div class="math notranslate nohighlight">
\begin{equation}
D_1(x) = x W_{1} \\
F(\{W\}, \{b\}; x) = D_1(x) W_{2}
\end{equation}</div><p>Assume \( x \) represents a single piece of input-data, and has a shape <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">D_full)</span></code>, \( W_{1} \) has shape <code class="docutils literal notranslate"><span class="pre">(D_full,</span> <span class="pre">D_hidden)</span></code>, \( W_{2} \) has shape <code class="docutils literal notranslate"><span class="pre">(D_hidden,</span> <span class="pre">D_full)</span></code>, and <code class="docutils literal notranslate"><span class="pre">D_hidden</span></code> &lt; <code class="docutils literal notranslate"><span class="pre">D_full</span></code>. The first layer can be thought to “encode” the input \( x \) into a smaller dimension of size <code class="docutils literal notranslate"><span class="pre">D_hidden</span></code>. The second layer then “decodes” the encoding by mapping it back to the original dimension of size <code class="docutils literal notranslate"><span class="pre">D_full</span></code>.</p>
<p>The reason we restrict ourselves to linear activations is that once when we apply an autoencoder to word embeddings, we will want to maintain linear relationships for visualizing word embedding relationships.</p>
<p>Once we have completely trained our autoencoder, we can simply chop off the decoder and use the encoder to generate our desired dense representations.</p>
<p>Complete the <code class="docutils literal notranslate"><span class="pre">LinearAutoencoder</span></code> MyNN class below.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class LinearAutoencoder:
    def __init__(self, D_full, D_hidden):
        &quot;&quot;&quot; This initializes all of the layers in our model, and sets them
        as attributes of the model.

        Parameters
        ----------
        D_full : int
            The size of the inputs.

        D_hidden : int
            The size of the &#39;bottleneck&#39; layer (i.e., the reduced dimensionality).
        &quot;&quot;&quot;
        # Initialize the encoder and decorder dense layers using the `he_normal` initialization
        # schemes.
        # What should the input and output dimensions of each layer be?
        # STUDENT CODE HERE

    def __call__(self, x):
        &#39;&#39;&#39;Passes data as input to our model, performing a &quot;forward-pass&quot;.

        This allows us to conveniently initialize a model `m` and then send data through it
        to be classified by calling `m(x)`.

        Parameters
        ----------
        x : Union[numpy.ndarray, mygrad.Tensor], shape=(M, D_full)
            A batch of data consisting of M pieces of data,
            each with a dimentionality of D_full.

        Returns
        -------
        mygrad.Tensor, shape=(M, D_full)
            The model&#39;s prediction for each of the M pieces of data.
        &#39;&#39;&#39;
        # keep in mind that this is a linear model - there is no &quot;activation function&quot;
        # involved here
        # STUDENT CODE HERE

    @property
    def parameters(self):
        &quot;&quot;&quot; A convenience function for getting all the parameters of our model.

        This can be accessed as an attribute, via `model.parameters`

        Returns
        -------
        Tuple[Tensor, ...]
            A tuple containing all of the learnable parameters for our model &quot;&quot;&quot;
        # STUDENT CODE HERE
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="2-Our-Data">
<h2>2 Our Data<a class="headerlink" href="#2-Our-Data" title="Permalink to this headline">¶</a></h2>
<p>We will use the Iris dataset, in which each datum is a 4-dimensional vector, and train an Autoencoder that will learn to compress the data into a 2-dimensional space. By reducing the dimensionality of the data, we will be able to visually identify clusters within the dataset.</p>
<p>The Iris dataset consists of 150 4-dimensional feature vectors describing three classes of Iris flowers. Each sample is a row vector <span class="math">\begin{equation}
\vec{x}=\begin{bmatrix}\text{sepal length} & \text{sepal width} & \text{petal length} & \text{petal width}\end{bmatrix}
\end{equation}</span></p>
<p>The Iris dataset contains data on three species of Iris. Each species has distinct features, and so should form clusters among the species.</p>
<p>Similar to our work in Week 2, zero center the data and scale by dividing by the standard deviation. Also make sure to check the shape of the data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>iris = np.load(&quot;./dat/iris_data.npy&quot;)

# STUDENT CODE HERE
</pre></div>
</div>
</div>
<p>Set up a noggin plotter to display the loss metric. Use <code class="docutils literal notranslate"><span class="pre">max_fraction_spent_plotting=.75</span></code>. Note there’s no additional accuracy metric since this is a regression problem instead of a classification task.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># STUDENT CODE HERE
</pre></div>
</div>
</div>
<p>Create a LinearAutoencoder with <code class="docutils literal notranslate"><span class="pre">D_hidden=2</span></code> and train with MyNN’s <code class="docutils literal notranslate"><span class="pre">mean_squared_loss</span></code>. You probably will only need 500 or less epochs. Try using a batch-size of 25.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># STUDENT CODE HERE
</pre></div>
</div>
</div>
<p>To obtain a reduced-dimensional embedding of a datum <strong>only apply the encoder</strong> to that datum. That is, do not perform a full forward pass of your model - instead, only apply the first dense layer to the dataset.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>with mg.no_autodiff:
    # STUDENT CODE HERE
</pre></div>
</div>
</div>
<p>Now use the below code to plot your reduced-dimensionality dataset. The plot will color the three different species of iris included in the dataset.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>names = [&#39;iris_satosa&#39;, &#39;iris_versicolor&#39;, &#39;iris_virginica&#39;]
colors = [&#39;red&#39;, &#39;green&#39;, &#39;blue&#39;]

fig, ax = plt.subplots()
for i in range(3):
    x = reduced[i*50:(i+1)*50, 0]
    y = reduced[i*50:(i+1)*50, 1]
    ax.scatter(x, y, c=colors[i], label=names[i])
ax.grid()
ax.legend()
</pre></div>
</div>
</div>
<p>Let’s take a moment to think about what our autoencoder is doing here. Just as when we constructed a one-layer dense network for the tendril dataset, which found three linear separators for the three tendrils, our autoencoder is finding a linear separator of the data. Because our hidden layer is 2-dimensional, the linear separator is a 2-dimensional plane in the original 4-dimensional space. The autoencoder then projects the original 4-dimensional data down into 2 dimensions. This projection is
what is plotted above.</p>
<p>What information are we now able to deduce from our now reduced data? Taking a step away from NLP, what uses might this dimensionality reduction have in data analysis? Discuss with a partner.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Ryan Soklaski

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>